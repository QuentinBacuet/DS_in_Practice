{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,BatchNormalization\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import pi\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.plotting import figure, show, output_file\n",
    "\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOURS_IN_DAY = 24\n",
    "MINUTES_IN_HOUR = 60\n",
    "SECONDS_IN_MINUTE = 60\n",
    "AGGREGATION_PERIOD = 30 #Model uses 30 minutes candles\n",
    "\n",
    "DAY_WINDOW = int(HOURS_IN_DAY * MINUTES_IN_HOUR / AGGREGATION_PERIOD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force CPU usage\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "num_cores = 8\n",
    "\n",
    "config = tf.ConfigProto(intra_op_parallelism_threads=num_cores,\\\n",
    "        inter_op_parallelism_threads=num_cores, allow_soft_placement=True,\\\n",
    "        device_count = {'CPU' : 1, 'GPU' : 0})\n",
    "session = tf.Session(config=config)\n",
    "K.set_session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For plot\n",
    "\n",
    "def prepare_standardplot(title, xlabel):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    fig.suptitle(title)\n",
    "    ax1.set_ylabel('categorical cross entropy')\n",
    "    ax1.set_xlabel(xlabel)\n",
    "    ax1.set_yscale('log')\n",
    "    ax2.set_ylabel('accuracy [% correct]')\n",
    "    ax2.set_xlabel(xlabel)\n",
    "    return fig, ax1, ax2\n",
    "\n",
    "def finalize_standardplot(fig, ax1, ax2):\n",
    "    ax1handles, ax1labels = ax1.get_legend_handles_labels()\n",
    "    if len(ax1labels) > 0:\n",
    "        ax1.legend(ax1handles, ax1labels)\n",
    "    ax2handles, ax2labels = ax2.get_legend_handles_labels()\n",
    "    if len(ax2labels) > 0:\n",
    "        ax2.legend(ax2handles, ax2labels)\n",
    "    fig.tight_layout()\n",
    "    plt.subplots_adjust(top=0.9)\n",
    "\n",
    "def plot_history(history, title):\n",
    "    fig, ax1, ax2 = prepare_standardplot(title, 'epoch')\n",
    "    ax1.plot(history.history['loss'], label = \"training\")\n",
    "    ax2.plot(history.history['binary_accuracy'], label = \"training\")\n",
    "    finalize_standardplot(fig, ax1, ax2)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_market_values(dataframe, aggregation_period, unix_time=False):\n",
    "    \"\"\"\n",
    "    timestamp / open / high / low / close / volume btc / volume currency / weighted price\n",
    "    \"\"\"    \n",
    "    data = dataframe.copy()\n",
    "    aggregation_factor = aggregation_period * SECONDS_IN_MINUTE\n",
    "    \n",
    "    if not unix_time:\n",
    "        data.Timestamp = data.Timestamp.astype(np.int64) // 10**9\n",
    "    \n",
    "    data = data.groupby(data.Timestamp // aggregation_factor).agg({\n",
    "        'Open' : 'first',\n",
    "        'High' : np.max,\n",
    "        'Low' : np.min,\n",
    "        'Close' : 'last',\n",
    "        'Volume_(BTC)' : np.sum ,\n",
    "        'Volume_(Currency)' : np.sum,\n",
    "        'Weighted_Price' : np.mean,\n",
    "    }).reset_index()\n",
    "    \n",
    "    data.Timestamp *= aggregation_factor\n",
    "    \n",
    "    if not unix_time:\n",
    "        data.Timestamp = pd.to_datetime(data.Timestamp, unit='s')\n",
    "    \n",
    "    return data\n",
    "\n",
    "def first_in_window(dataframe, aggregation_period, unix_time=False):\n",
    "    \"\"\"\n",
    "    timestamp / open / high / low / close / volume btc / volume currency / weighted price\n",
    "    \"\"\"    \n",
    "    data = dataframe.copy()\n",
    "    aggregation_factor = aggregation_period * SECONDS_IN_MINUTE\n",
    "    \n",
    "    if not unix_time:\n",
    "        data.Timestamp = data.Timestamp.astype(np.int64) // 10**9\n",
    "            \n",
    "    data = data.groupby(data.Timestamp // aggregation_factor).first().reset_index(drop=True)\n",
    "            \n",
    "    if not unix_time:\n",
    "        data.Timestamp = pd.to_datetime(data.Timestamp, unit='s')\n",
    "    \n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_part1 = pd.read_csv('Data/bitstampUSD_1-min_data_2012-01-01_to_2018-01-08.csv')\n",
    "df_raw_part2 = pd.read_csv('Data/bitstampUSD_30-min_data_january.csv', date_parser=True)\n",
    "\n",
    "# Aggregate first part of data into chunks of 30 mins, second part already aggregated\n",
    "df_p1 = aggregate_market_values(df_raw_part1, 30, unix_time=True)\n",
    "df_p1.Timestamp = pd.to_datetime(df_p1.Timestamp, unit='s')\n",
    "\n",
    "df_p2 = df_raw_part2\n",
    "df_p2.Timestamp = pd.to_datetime(df_p2.Timestamp)\n",
    "\n",
    "df_raw = pd.concat([df_p1, df_p2]).reset_index(drop=True)\n",
    "\n",
    "display(df_raw[105370:105372])\n",
    "display(df_raw.tail())\n",
    "print(df_raw.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = df_raw.copy()\n",
    "\n",
    "aggregation_factor = 24 * 60 #24h candles\n",
    "\n",
    "df_plot = aggregate_market_values(df_plot, 12 * 60)\n",
    "\n",
    "inc = df_plot.Close >= df_plot.Open\n",
    "dec = df_plot.Open > df_plot.Close\n",
    "barWidth = 0.66 * aggregation_factor * 60 * 1000 # 30 minutes in ms\n",
    "\n",
    "TOOLS = \"pan,wheel_zoom,box_zoom,reset,save\"\n",
    "\n",
    "p = figure(x_axis_type=\"datetime\", tools=TOOLS, plot_width=990, title = \"MSFT Candlestick\")\n",
    "p.xaxis.major_label_orientation = pi/4\n",
    "p.grid.grid_line_alpha=0.3\n",
    "\n",
    "p.segment(df_plot.Timestamp, df_plot.High, df_plot.Timestamp, df_plot.Low, color=\"black\")\n",
    "p.vbar(df_plot.Timestamp[inc], barWidth, df_plot.Open[inc], df_plot.Close[inc], fill_color=\"#48D922\", line_color=\"black\")\n",
    "p.vbar(df_plot.Timestamp[dec], barWidth, df_plot.Open[dec], df_plot.Close[dec], fill_color=\"#FF2828\", line_color=\"black\")\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective \n",
    "\n",
    "We aim to predict price changes across intervals of 24 hours. More specifically, at the end of each day, the model should predict the price of Bitcoin in the following 24 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_MA_n_days_age(num_days):\n",
    "    num_days_str = str(num_days)\n",
    "    \n",
    "    df[['Open_W_MA_'+num_days_str,'High_W_MA_'+num_days_str,'Low_W_MA_'+num_days_str,'Close_W_MA_'+num_days_str]] = df[['Open_W','High_W','Low_W','Close_W']].rolling(window=day_window * num_days).mean()\n",
    "    df[['Open_MA_'+num_days_str,'High_MA_'+num_days_str,'Low_MA_'+num_days_str,'Close_MA_'+num_days_str]] = df[['Open','High','Low','Close']].rolling(window=day_window * num_days).mean()\n",
    "    df[['Open_EMA_'+num_days_str,'High_EMA_'+num_days_str,'Low_EMA_'+num_days_str,'Close_EMA_'+num_days_str]] = df[['Open','High','Low','Close']].ewm(span=day_window * num_days).mean()\n",
    "\n",
    "    df[['Open_MAX_'+num_days_str,'High_MAX_'+num_days_str,'Low_MAX_'+num_days_str,'Close_MAX_'+num_days_str]] = df[['Open','High','Low','Close']].rolling(window=day_window * num_days).max()\n",
    "    df[['Open_MIN_'+num_days_str,'High_MIN_'+num_days_str,'Low_MIN_'+num_days_str,'Close_MIN_'+num_days_str]] = df[['Open','High','Low','Close']].rolling(window=day_window * num_days).min()\n",
    "\n",
    "    df['Open_TENKAN_'+num_days_str] = 0.5 * (df['Open_MIN_'+num_days_str] + df['Open_MAX_'+num_days_str])\n",
    "    df['High_TENKAN_'+num_days_str] = 0.5 * (df['High_MIN_'+num_days_str] + df['High_MAX_'+num_days_str])\n",
    "    df['Low_TENKAN_'+num_days_str] = 0.5 * (df['Low_MIN_'+num_days_str] + df['Low_MAX_'+num_days_str])\n",
    "    df['Close_TENKAN_'+num_days_str] = 0.5 * (df['Close_MIN_'+num_days_str] + df['Close_MAX_'+num_days_str])\n",
    "\n",
    "def add_prices_n_days_ago(num_days):\n",
    "    num_days_str = str(num_days)\n",
    "    df[['Open_S_'+num_days_str,'High_S_'+num_days_str,'Low_S_'+num_days_str,'Close_S_'+num_days_str]] = df[['Open','High','Low','Close']].shift(day_window * num_days)\n",
    "\n",
    "def create_labels(data):\n",
    "    r = data.copy()\n",
    "    r['Label'] = r['Close'].shift(-DAY_WINDOW)\n",
    "    \n",
    "    return r\n",
    "\n",
    "def mean_square_loss(predicted_labels, true_labels):\n",
    "    assert len(predicted_labels) == len(true_labels)\n",
    "    return np.mean((predicted_labels - true_labels)**2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple model\n",
    "\n",
    "To assess the performance of our model, we devise a simple naïve model as a benchmark. Our simple model looks at the price change in the last 24H and assume that this change will repeat in the next 24H. More specifically, let $P_p, P_c, P_f$ be respectively the previous, current and future price of Bitcoin (in intervals of 24 hours). We have:\n",
    "\n",
    "$$ P_f = P_c + (P_c - P_p) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_predictor(previous, current):\n",
    "    return current.Close + ((current.Close - previous.Close) / previous.Close) * current.Close\n",
    "\n",
    "def naive_predict(data):  \n",
    "    P_c = data.Close\n",
    "    P_p = data.Close.shift(DAY_WINDOW)\n",
    "    \n",
    "    return pd.concat([data.Timestamp, 2 * P_c +  - P_p], axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = pd.DataFrame(create_labels(df_raw).Label)\n",
    "predicted_labels = naive_predict(df_raw)\n",
    "\n",
    "join = pd.concat([true_labels, predicted_labels], axis=1).dropna()\n",
    "\n",
    "print(mean_square_loss(np.log(join.Label), np.log(join.Close)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_n_points = -6000\n",
    "\n",
    "p = figure(x_axis_type=\"datetime\", tools=TOOLS, plot_width=990, title = \"MSFT Candlestick\")\n",
    "p.xaxis.major_label_orientation = pi/4\n",
    "p.grid.grid_line_alpha=0.3\n",
    "\n",
    "p.line(df_raw.Timestamp[last_n_points:], np.log(df_raw.Close[last_n_points:]), line_color='blue')\n",
    "p.line(df_raw.Timestamp[last_n_points:], np.log(naive_predict(df_raw).Close[last_n_points:]), line_color='red')\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_aggregation = 30\n",
    "\n",
    "df = aggregate_market_values(df_raw.copy(), window_aggregation)\n",
    "\n",
    "df = df.drop('Timestamp',1)\n",
    "#df = df.drop('Weighted_Price',1)\n",
    "\n",
    "\n",
    "labels = np.log(create_labels(df).Label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Open_W','High_W','Low_W','Close_W']] = df[['Open','High','Low','Close']].divide(df['Volume_(BTC)'],axis = 0)\n",
    "\n",
    "#df[['Open','High','Low','Close']] = df[['Open','High','Low','Close']].apply(lambda x: np.log(x))\n",
    "\n",
    "add_prices_n_days_ago(1)\n",
    "add_prices_n_days_ago(2)\n",
    "add_prices_n_days_ago(3)\n",
    "\n",
    "add_MA_n_days_age(5)\n",
    "add_MA_n_days_age(10)\n",
    "add_MA_n_days_age(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plusieurs y gains selon différents temps + vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean = (df['Open'] + df['Close']) * 0.5\n",
    "#res = mean.shift(day_window)\n",
    "\n",
    "#df['y'] = ((mean - res) > 0).astype(int)\n",
    "df = pd.concat([df, labels], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display(df.sample(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.dropna(how ='any')\n",
    "\n",
    "labels = df.Label\n",
    "df = (df-df.mean())/df.std()\n",
    "df.Label = labels\n",
    "df = df.reset_index()\n",
    "df = df.drop('index',1)\n",
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_test2=int(0.8*len(df.index))\n",
    "window = day_window * 30 * 2\n",
    "\n",
    "index = df.index\n",
    "index = index[0:length_test2]\n",
    "\n",
    "indexList = [index[i:min(i + window,len(index))] for i in range(0, len(index), window)]\n",
    "trainIndex = []\n",
    "testIndex = []\n",
    "\n",
    "for i in range(len(indexList)):\n",
    "    if i%9 != 0:\n",
    "        trainIndex += indexList[i].tolist()\n",
    "    else:\n",
    "        testIndex  += indexList[i].tolist()\n",
    "        \n",
    "print(len(trainIndex+testIndex) == len(index))\n",
    "print(len(indexList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=df.iloc[trainIndex,:]\n",
    "test1=df.iloc[testIndex,:]\n",
    "test2=df.drop(train.index).drop(test1.index)\n",
    "\n",
    "train_x = train.drop('Label',1)\n",
    "train_y = train['Label']\n",
    "test_x1 = test1.drop('Label',1)\n",
    "test_y1 = test1['Label']\n",
    "test_x2 = test2.drop('Label',1)\n",
    "test_y2 = test2['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=95, activation='selu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='selu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='selu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='adam')\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs = 30, verbose=1)\n",
    "scores1 = model.evaluate(test_x1, test_y1, verbose=0)\n",
    "scores2 = model.evaluate(test_x2, test_y2, verbose=0)\n",
    "\n",
    "model.save('my_model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_history(history,\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scores1)\n",
    "print(scores2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(test_x2)\n",
    "\n",
    "\n",
    "last_n_points = -len(prediction)\n",
    "\n",
    "p = figure(x_axis_type=\"datetime\", tools=TOOLS, plot_width=990, title = \"MSFT Candlestick\")\n",
    "p.xaxis.major_label_orientation = pi/4\n",
    "p.grid.grid_line_alpha=0.3\n",
    "\n",
    "p.line(range(len(prediction)), np.squeeze(prediction), line_color='blue')\n",
    "p.line(range(len(prediction)), np.log(df_raw.Close[last_n_points:]), line_color='red')\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = []\n",
    "not_correct = []\n",
    "\n",
    "prediction = model.predict(test_x2)\n",
    "\n",
    "for i in range(len(prediction)):\n",
    "    if prediction[i].round() == test_y2.values[i]:\n",
    "        correct.append([i,test_x2['Open'].values[i]])\n",
    "    else:\n",
    "        not_correct.append([i,test_x2['Open'].values[i]])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10),dpi = 80)\n",
    "a,b = zip(*correct)\n",
    "ax.plot(a,b, '.r',markersize=0.2)\n",
    "a,b = zip(*not_correct)\n",
    "ax.plot(a,b, '.b',markersize=0.2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investing using the model\n",
    "We use the model to apply the following simple investment strategy. At the end of each day, we take either a long or short position for $100. No matter what happens, the position is liquidated after 24H. Of course, the choice of the position is dependent on the price increase or decrease of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_amount = 100 #dollars\n",
    "\n",
    "def compute_investment_return(prices, decisions):\n",
    "    prices_in_24h = prices.shift(-DAY_WINDOW)\n",
    "    return np.sum( ((prices_in_24h - prices)/prices) * daily_amount * decisions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The anarchist\n",
    "The anarchist decide whether to invest or not based on a (bit)coin flip:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum = 0\n",
    "prices = df_raw.iloc[test2.index].Close\n",
    "l = len(prices)\n",
    "for i in range(10000):\n",
    "    choices = 2 * np.random.choice(2, l) - 1\n",
    "    sum += compute_investment_return(prices, choices)\n",
    "\n",
    "print(sum / 10000.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#true_labels = pd.DataFrame(create_labels(df_24h).Label)\n",
    "predicted_labels = naive_predict( df_raw.iloc[test2.index].copy())\n",
    "predicted_labels.columns = ['Timestamp', 'Price_Prediction']\n",
    "\n",
    "prices = df_raw.iloc[test2.index].Close\n",
    "\n",
    "join = pd.concat([predicted_labels, prices], axis=1).dropna()\n",
    "join = first_in_window(join.copy(), 24*60)\n",
    "join['Decision'] = 2 * (join.Price_Prediction >= join.Close) - 1 # Long: 1 Short: -1\n",
    "display(join)\n",
    "\n",
    "decisions_simple = join.copy().Decision\n",
    "\n",
    "print(len(join))\n",
    "\n",
    "print(compute_investment_return(join.Close, join.Decision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = pd.DataFrame(np.exp(model.predict(test_x2)).squeeze())\n",
    "prediction.columns = ['Price_Prediction']\n",
    "prediction['previous'] = prediction.shift(DAY_WINDOW)\n",
    "\n",
    "prices = df_raw.iloc[test2.index][['Timestamp', 'Close']].reset_index(drop=True)\n",
    "\n",
    "join = pd.concat([prediction, prices], axis=1).dropna()\n",
    "join = first_in_window(join.copy(), 24*60)\n",
    "join['Decision'] = 2 * (join.Price_Prediction >= join.previous) - 1 # Long: 1 Short: -1\n",
    "display(join)\n",
    "\n",
    "decisions_nn = join.copy().Decision\n",
    "\n",
    "print(len(join))\n",
    "\n",
    "print(compute_investment_return(join.Close, join.Decision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(decisions_simple.values == decisions_nn[1:].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    " \n",
    "    \n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "\n",
    "    model = load_model('my_model.h5')\n",
    "    scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "    print(scores)\n",
    "    \n",
    "    del model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
