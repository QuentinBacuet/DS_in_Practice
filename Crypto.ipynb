{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,BatchNormalization\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import pi\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.plotting import figure, show, output_file\n",
    "\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SECONDS_IN_MINUTE = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Force CPU usage\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "num_cores = 8\n",
    "\n",
    "config = tf.ConfigProto(intra_op_parallelism_threads=num_cores,\\\n",
    "        inter_op_parallelism_threads=num_cores, allow_soft_placement=True,\\\n",
    "        device_count = {'CPU' : 1, 'GPU' : 0})\n",
    "session = tf.Session(config=config)\n",
    "K.set_session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For plot\n",
    "\n",
    "def prepare_standardplot(title, xlabel):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    fig.suptitle(title)\n",
    "    ax1.set_ylabel('categorical cross entropy')\n",
    "    ax1.set_xlabel(xlabel)\n",
    "    ax1.set_yscale('log')\n",
    "    ax2.set_ylabel('accuracy [% correct]')\n",
    "    ax2.set_xlabel(xlabel)\n",
    "    return fig, ax1, ax2\n",
    "\n",
    "def finalize_standardplot(fig, ax1, ax2):\n",
    "    ax1handles, ax1labels = ax1.get_legend_handles_labels()\n",
    "    if len(ax1labels) > 0:\n",
    "        ax1.legend(ax1handles, ax1labels)\n",
    "    ax2handles, ax2labels = ax2.get_legend_handles_labels()\n",
    "    if len(ax2labels) > 0:\n",
    "        ax2.legend(ax2handles, ax2labels)\n",
    "    fig.tight_layout()\n",
    "    plt.subplots_adjust(top=0.9)\n",
    "\n",
    "def plot_history(history, title):\n",
    "    fig, ax1, ax2 = prepare_standardplot(title, 'epoch')\n",
    "    ax1.plot(history.history['loss'], label = \"training\")\n",
    "    ax2.plot(history.history['binary_accuracy'], label = \"training\")\n",
    "    finalize_standardplot(fig, ax1, ax2)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def aggregate_market_values(dataframe, aggregation_period):\n",
    "    \"\"\"\n",
    "    timestamp / open / high / low / close / volume btc / volume currency / weighted price\n",
    "    \"\"\"\n",
    "    aggregation_factor = aggregation_period * SECONDS_IN_MINUTE\n",
    "    \n",
    "    ret = dataframe.groupby(dataframe.Timestamp // aggregation_factor).agg({\n",
    "        'Open' : 'first',\n",
    "        'High' : np.max,\n",
    "        'Low' : np.min,\n",
    "        'Close' : 'last',\n",
    "        'Volume_(BTC)' : np.sum ,\n",
    "        'Volume_(Currency)' : np.sum,\n",
    "        'Weighted_Price' : np.mean,\n",
    "    }).reset_index()\n",
    "    \n",
    "    ret.Timestamp *= aggregation_factor\n",
    "    \n",
    "    return ret\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv('Data/bitstampUSD_1-min_data_2012-01-01_to_2018-01-08.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(aggregate_market_values(df_raw[:100].copy(), 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_aggregation = 30\n",
    "day_window = int(24*60 / window_aggregation)\n",
    "\n",
    "df = aggregate_market_values(df_raw.copy(),window_aggregation)\n",
    "\n",
    "df = df.drop('Timestamp',1)\n",
    "#df = df.drop('Weighted_Price',1)\n",
    "\n",
    "df[['Open','High','Low','Close']] = df[['Open','High','Low','Close']].apply(lambda x: np.log(x))\n",
    "df = (df-df.mean())/df.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_MA_n_days_age(num_days):\n",
    "    num_days_str = str(num_days)\n",
    "    \n",
    "    df[['Open_W_MA_'+num_days_str,'High_W_MA_'+num_days_str,'Low_W_MA_'+num_days_str,'Close_W_MA_'+num_days_str]] = df[['Open_W','High_W','Low_W','Close_W']].rolling(window=day_window * num_days).mean()\n",
    "    df[['Open_MA_'+num_days_str,'High_MA_'+num_days_str,'Low_MA_'+num_days_str,'Close_MA_'+num_days_str]] = df[['Open','High','Low','Close']].rolling(window=day_window * num_days).mean()\n",
    "    df[['Open_EMA_'+num_days_str,'High_EMA_'+num_days_str,'Low_EMA_'+num_days_str,'Close_EMA_'+num_days_str]] = df[['Open','High','Low','Close']].ewm(span=day_window * num_days).mean()\n",
    "\n",
    "    df[['Open_MAX_'+num_days_str,'High_MAX_'+num_days_str,'Low_MAX_'+num_days_str,'Close_MAX_'+num_days_str]] = df[['Open','High','Low','Close']].rolling(window=day_window * num_days).max()\n",
    "    df[['Open_MIN_'+num_days_str,'High_MIN_'+num_days_str,'Low_MIN_'+num_days_str,'Close_MIN_'+num_days_str]] = df[['Open','High','Low','Close']].rolling(window=day_window * num_days).min()\n",
    "\n",
    "    df['Open_TENKAN_'+num_days_str] = 0.5 * (df['Open_MIN_'+num_days_str] + df['Open_MAX_'+num_days_str])\n",
    "    df['High_TENKAN_'+num_days_str] = 0.5 * (df['High_MIN_'+num_days_str] + df['High_MAX_'+num_days_str])\n",
    "    df['Low_TENKAN_'+num_days_str] = 0.5 * (df['Low_MIN_'+num_days_str] + df['Low_MAX_'+num_days_str])\n",
    "    df['Close_TENKAN_'+num_days_str] = 0.5 * (df['Close_MIN_'+num_days_str] + df['Close_MAX_'+num_days_str])\n",
    "\n",
    "def add_prices_n_days_ago(num_days):\n",
    "    num_days_str = str(num_days)\n",
    "    df[['Open_S_'+num_days_str,'High_S_'+num_days_str,'Low_S_'+num_days_str,'Close_S_'+num_days_str]] = df[['Open','High','Low','Close']].shift(day_window * num_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Open_W','High_W','Low_W','Close_W']] = df[['Open','High','Low','Close']].divide(df['Volume_(BTC)'],axis = 0)\n",
    "\n",
    "add_prices_n_days_ago(1)\n",
    "add_prices_n_days_ago(2)\n",
    "add_prices_n_days_ago(3)\n",
    "\n",
    "add_MA_n_days_age(5)\n",
    "add_MA_n_days_age(10)\n",
    "add_MA_n_days_age(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plusieurs y gains selon diffÃ©rents temps + vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = (df['Open'] + df['Close']) * 0.5\n",
    "res = mean.shift(day_window)\n",
    "\n",
    "df['y'] = ((mean - res) > 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display(df.sample(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.dropna(how ='any')\n",
    "\n",
    "y = df.y\n",
    "df = (df-df.mean())/df.std()\n",
    "df.y = y\n",
    "df = df.reset_index()\n",
    "df = df.drop('index',1)\n",
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = aggregate_market_values(df_raw[-1000:].copy(), 60)\n",
    "\n",
    "df_plot['Date'] = pd.to_datetime(df_plot.Timestamp, unit='s')\n",
    "\n",
    "display(df_plot.head())\n",
    "\n",
    "inc = df_plot.Close >= df_plot.Open\n",
    "dec = df_plot.Open > df_plot.Close\n",
    "barWidth = 0.66 * 60 * 60*1000 # one minute in ms\n",
    "\n",
    "TOOLS = \"pan,wheel_zoom,box_zoom,reset,save\"\n",
    "\n",
    "p = figure(x_axis_type=\"datetime\", tools=TOOLS, plot_width=990, title = \"MSFT Candlestick\")\n",
    "p.xaxis.major_label_orientation = pi/4\n",
    "p.grid.grid_line_alpha=0.3\n",
    "\n",
    "p.segment(df_plot.Date, df_plot.High, df_plot.Date, df_plot.Low, color=\"black\")\n",
    "p.vbar(df_plot.Date[inc], barWidth, df_plot.Open[inc], df_plot.Close[inc], fill_color=\"#48D922\", line_color=\"black\")\n",
    "p.vbar(df_plot.Date[dec], barWidth, df_plot.Open[dec], df_plot.Close[dec], fill_color=\"#FF2828\", line_color=\"black\")\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_test2=int(0.8*len(df.index))\n",
    "window = day_window*30 * 2\n",
    "\n",
    "index = df.index\n",
    "index= index[0:length_test2]\n",
    "\n",
    "indexList = [index[i:min(i + window,len(index))] for i in range(0, len(index), window)]\n",
    "trainIndex = []\n",
    "testIndex = []\n",
    "\n",
    "for i in range(len(indexList)):\n",
    "    if i%9 != 0:\n",
    "        trainIndex += indexList[i].tolist()\n",
    "    else:\n",
    "        testIndex  += indexList[i].tolist()\n",
    "        \n",
    "print(len(trainIndex+testIndex) == len(index))\n",
    "print(len(indexList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train=df.iloc[trainIndex,:]\n",
    "test1=df.iloc[testIndex,:]\n",
    "test2=df.drop(train.index).drop(test1.index)\n",
    "\n",
    "train_x = train.drop('y',1)\n",
    "train_y = train['y']\n",
    "test_x1 = test1.drop('y',1)\n",
    "test_y1 = test1['y']\n",
    "test_x2 = test2.drop('y',1)\n",
    "test_y2 = test2['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=95, activation='selu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='selu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['binary_accuracy'])\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs = 10, verbose=1)\n",
    "scores1 = model.evaluate(test_x1, test_y1, verbose=0)\n",
    "scores2 = model.evaluate(test_x2, test_y2, verbose=0)\n",
    "\n",
    "model.save('my_model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history,\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scores1)\n",
    "print(scores2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = []\n",
    "not_correct = []\n",
    "\n",
    "prediction = model.predict(test_x2)\n",
    "\n",
    "for i in range(len(prediction)):\n",
    "    if prediction[i].round() == test_y2.values[i]:\n",
    "        correct.append([i,test_x2['Open'].values[i]])\n",
    "    else:\n",
    "        not_correct.append([i,test_x2['Open'].values[i]])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10),dpi = 80)\n",
    "a,b = zip(*correct)\n",
    "ax.plot(a,b, '.r',markersize=0.2)\n",
    "a,b = zip(*not_correct)\n",
    "ax.plot(a,b, '.b',markersize=0.2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    " \n",
    "    \n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "\n",
    "    model = load_model('my_model.h5')\n",
    "    scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "    print(scores)\n",
    "    \n",
    "    del model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
